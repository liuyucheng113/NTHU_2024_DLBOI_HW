{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh8dy5kvfrMSIH51MRs5P8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyucheng113/NTHU_2024_DLBOI_HW/blob/main/hw4_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe0kiwqXih-s"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Track total execution time\n",
        "overall_start = time.time()\n",
        "\n",
        "# Hyperparameters\n",
        "hyperparameters = {\n",
        "    'learning_rate': 1e-4,\n",
        "    'epochs': 20,\n",
        "    'batch_size': 32,\n",
        "    'weight_decay': 1e-5,\n",
        "}\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Paths to dataset\n",
        "train_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\train'\n",
        "val_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\val'\n",
        "test_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\test'\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "\n",
        "# Initialize DenseNet-121 as a fixed feature extractor\n",
        "densenet_model = models.densenet121(pretrained=True)\n",
        "for param in densenet_model.parameters():\n",
        "    param.requires_grad = False  # Freeze all layers\n",
        "densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, 2)  # Modify for 2 classes\n",
        "densenet_model = densenet_model.to(device)\n",
        "\n",
        "# Define loss and optimizer for the final layer only\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(densenet_model.classifier.parameters(), lr=hyperparameters['learning_rate'], weight_decay=hyperparameters['weight_decay'])\n",
        "\n",
        "# Training and validation loops with time tracking\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "# Track total training time\n",
        "total_start = time.time()\n",
        "\n",
        "# Training function\n",
        "def train_one_epoch(model, train_loader):\n",
        "    model.train()\n",
        "    running_loss, all_preds, all_labels = 0.0, [], []\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = accuracy_score(all_labels, all_preds) * 100\n",
        "    return train_loss, train_acc\n",
        "\n",
        "# Validation function\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    running_loss, all_preds, all_labels = 0.0, [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = accuracy_score(all_labels, all_preds) * 100\n",
        "    return val_loss, val_acc\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(hyperparameters['epochs']):\n",
        "    epoch_start = time.time()  # Track each epoch time\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train_one_epoch(densenet_model, train_loader)\n",
        "    val_loss, val_acc = validate(densenet_model, val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Save the best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(densenet_model.state_dict(), 'densenet_fixed_feature_extractor.pth')\n",
        "\n",
        "    epoch_end = time.time()\n",
        "    epoch_duration = epoch_end - epoch_start\n",
        "    print(f\"Epoch [{epoch+1}/{hyperparameters['epochs']}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Epoch Time: {epoch_duration:.2f}s\")\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - total_start\n",
        "print(f\"Total Training Time: {total_time:.2f}s\")\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('DenseNet as Fixed Feature Extractor - Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('DenseNet as Fixed Feature Extractor - Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on test set\n",
        "def evaluate(model, test_loader):\n",
        "    model.load_state_dict(torch.load('densenet_fixed_feature_extractor.pth'))\n",
        "    model.eval()\n",
        "    test_loss, all_preds, all_labels = 0.0, [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    avg_test_acc = accuracy_score(all_labels, all_preds) * 100\n",
        "    return avg_test_loss, avg_test_acc\n",
        "\n",
        "avg_test_loss, avg_test_acc = evaluate(densenet_model, test_loader)\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.2f}%\")\n",
        "\n",
        "# Print total execution time\n",
        "overall_end = time.time()\n",
        "overall_duration = overall_end - overall_start\n",
        "print(f\"Total Execution Time: {overall_duration:.2f}s\")\n",
        "#%%\n",
        "import time  # Import time module for tracking computation time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparameters (grouped together)\n",
        "hyperparameters = {\n",
        "    'learning_rate': 1e-4,  # Learning rate\n",
        "    'epochs': 20,           # Number of epochs\n",
        "    'weight_decay': 1e-5,   # Weight decay (L2 regularization)\n",
        "    'batch_size': 32        # Batch size\n",
        "}\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Using\", gpu_count, \"GPUs\")\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "\n",
        "# Paths to dataset\n",
        "train_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\train'\n",
        "val_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\val'\n",
        "test_path = r'C:\\Users\\Lab510\\Desktop\\chest_xray\\test'\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "\n",
        "# Load pre-trained ResNet-50 model\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)  # Modify for 2 classes\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer with weight decay (L2 regularization)\n",
        "optimizer = optim.Adam(resnet_model.fc.parameters(), lr=hyperparameters['learning_rate'], weight_decay=hyperparameters['weight_decay'])\n",
        "\n",
        "# Lists to store loss and accuracy values\n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies, val_accuracies = [], []\n",
        "\n",
        "# Training and Validation function with time tracking\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    start_time = time.time()  # Track total training time\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()  # Track each epoch time\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate train loss and accuracy\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        epoch_end = time.time()  # End of epoch time tracking\n",
        "        epoch_duration = epoch_end - epoch_start\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, \"\n",
        "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}, Epoch Time: {epoch_duration:.2f}s\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Total Training Time: {total_time:.2f}s\")\n",
        "\n",
        "# Train and evaluate ResNet-50 as a fixed feature extractor\n",
        "num_epochs = hyperparameters['epochs']\n",
        "train_model(resnet_model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs)\n",
        "\n",
        "# Save the ResNet model\n",
        "model_path = 'resnet_fixed_feature_extractor.pth'\n",
        "torch.save(resnet_model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# Plot training and validation results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('ResNet Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('ResNet Accuracy Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluation function for test set\n",
        "def evaluate(model, device, data_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(data_loader)\n",
        "    avg_test_acc = accuracy_score(all_labels, all_preds) * 100  # Accuracy in %\n",
        "    return avg_test_loss, avg_test_acc\n",
        "\n",
        "# Load model weights and evaluate on test set\n",
        "resnet_model.load_state_dict(torch.load(model_path))\n",
        "resnet_model = resnet_model.to(device)\n",
        "avg_test_loss, avg_test_acc = evaluate(resnet_model, device, test_loader)\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.2f}%\")"
      ]
    }
  ]
}